{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "import functools\n",
    "\n",
    "\n",
    "#---> these functions are used for resetting the object attribute.\n",
    "def rgetattr(obj, attr, *args):\n",
    "    def _getattr(obj, attr):\n",
    "        return getattr(obj, attr, *args)\n",
    "    return functools.reduce(_getattr, [obj] + attr.split('.'))\n",
    "\n",
    "def rsetattr(obj, attr, val):\n",
    "    pre, _, post = attr.rpartition('.')\n",
    "    return setattr(rgetattr(obj, pre) if pre else obj, post, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "\n",
    "import functools\n",
    "import math\n",
    "\n",
    "\n",
    "#-----------------------> (added on 31-07-2020)\n",
    "class AQuantizer(Function):    \n",
    "    @staticmethod\n",
    "    def forward(ctx, tensor, shift_v, N, a_sgn):#-->a_sgn:1X1 tensor\n",
    "        #tensor1 = torch.unsqueeze(tensor,0).repeat(N,1,1,1,1)\n",
    "        tensor1 = torch.cat(N*[torch.unsqueeze(tensor,0)]) #--> same as the above but the above giving issue with backward pass.\n",
    "        #shift_v = shift_v.unsqueeze(1).unsqueeze(1).unsqueeze(1).unsqueeze(1) # shape : NX1X1X1X1\n",
    "        shift_v = shift_v.unsqueeze(1).unsqueeze(3).unsqueeze(3) # shape : NX1XCX1X1\n",
    "\n",
    "        x = tensor1-shift_v\n",
    "        ctx.save_for_backward(x, a_sgn)\n",
    "        y = a_sgn[0]*torch.sign(x) + (1-a_sgn[0])*x\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):        \n",
    "        # We return as many input gradients as there were arguments.\n",
    "        # Gradients of non-Tensor arguments to forward must be None.\n",
    "        \n",
    "        g_o = grad_output.clone() #this is a 5D tensor : Nxbatch-sizexchannelxRxC\n",
    "        #print(ctx.saved_tensors)\n",
    "        t, a_sgn = ctx.saved_tensors #--> otherwise reyurning a tuple\n",
    "        \n",
    "        t1 = t.clone()          #--->new\n",
    "        if a_sgn[0]>0:\n",
    "            t1 = -((1+a_sgn[0])/a_sgn[0])*torch.abs(t1)+2 #--->new\n",
    "        else:\n",
    "            t1=0*torch.abs(t1) #--> just make it zero.\n",
    "        \n",
    "        t[torch.abs(t)<=a_sgn[0]] = 1.0\n",
    "        t[torch.abs(t)>a_sgn[0]] = 0.0 \n",
    "        \n",
    "        t = t1*t                #--->new\n",
    "        \n",
    "        grad_input=grad_output*(1-a_sgn[0]) + grad_output*(a_sgn[0])*t\n",
    "        grad_input=(1/grad_output.size()[0])*torch.sum(grad_input, dim=0)\n",
    "        \n",
    "        #average the gradient along the batch-size dimension\n",
    "        #grad_a = (1/t.size()[1])*(torch.sum(torch.sum(torch.sum(torch.sum(g_o,dim=1),dim=1),dim=1),dim=1))*-1.0\n",
    "        grad_a = (1/t.size()[1])*(torch.sum(torch.sum(torch.sum(g_o,dim=1),dim=2),dim=2))*-1.0 #--> NXC shift_v parameter grad\n",
    "        #N-element tensor returned.\n",
    "        return grad_input , grad_a, None, None\n",
    "\n",
    "#-----------------------> (added on 27=07-2020)\n",
    "class ActQuantizer(nn.Module) :\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ActQuantizer, self).__init__()\n",
    "        self.shift_init = kwargs['shift_init']\n",
    "        self.N = kwargs['N']\n",
    "        #self.a_sgn = kwargs['a_sgn']\n",
    "        #self.shift_v = nn.Parameter(torch.from_numpy(np.array(self.shift_init)).float()) #initial clip_v value\n",
    "        self.shift_v = nn.Parameter(self.shift_init.float()) #initial clip_v value\n",
    "        #self.register_buffer('shift_v', torch.from_numpy(np.array(self.shift_init)).float())        \n",
    "        \n",
    "        #self.register_backward_hook(self.backward_hook) #---> This is not called when backward_hook() is not called.\n",
    "    \n",
    "    def forward(self, input, a_sgn):\n",
    "        x = AQuantizer.apply(input,self.shift_v,self.N,a_sgn)#-->new addition\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WQuantizer(nn.Module):\n",
    "    \n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(WQuantizer, self).__init__()\n",
    "        self.M = kwargs['M']\n",
    "        self.register_buffer('u', torch.tensor(np.zeros( (self.M,1,1,1,1) ) ) )\n",
    "        for i in range(self.M):\n",
    "            self.u[i,0,0,0,0] = -1+2*(i-1)/(self.M-1)        \n",
    "        data = kwargs['data']\n",
    "        \n",
    "    def quantize(self, data):        \n",
    "        data = torch.unsqueeze(data,0) \n",
    "        B_concat = torch.sign(data-torch.mean(data) + self.u*torch.std(data)).float() #-->new (all Bi's along 0 th dimension)       \n",
    "        #calculate 'a'        \n",
    "        # the .float() was added to ensure all operations in float() mode. Otherwise, it was giving error saying input is float and weight double()        \n",
    "        W1 = torch.reshape(data,(-1,1))           #-->added .float()\n",
    "        B1 = torch.reshape(B_concat,(self.M,-1)) #-->new\n",
    "        B = torch.transpose(B1,0,1)              #-->new\n",
    "        a = torch.matmul(torch.matmul(torch.pinverse(torch.matmul(torch.transpose(B,0,1),B)),torch.transpose(B,0,1)),W1).float()\n",
    "        \n",
    "        return a,B_concat\n",
    "\n",
    "class QConv2d(nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, quant_args=None, init_args=None, *kargs, **kwargs):\n",
    "        super(QConv2d, self).__init__(*kargs, **kwargs)\n",
    "        # ....................................................weight quantization\n",
    "        self.weight.data = init_args['weight_data']\n",
    "        if kwargs['bias'] == True:\n",
    "            self.bias.data = init_args['bias_data']\n",
    "        self.M = init_args['M']\n",
    "        w_qargs = {'M':self.M}\n",
    "        self.quantizer = WQuantizer (data = self.weight.data, **w_qargs)\n",
    "        \n",
    "        a_copy = np.zeros((self.M,1)) #--> new\n",
    "        a_copy[0][0]=1.0 #--> new\n",
    "        self.register_buffer('a', torch.tensor(a_copy)) #--> new\n",
    "        #self.register_buffer('a', torch.tensor([[1],[0],[0]])) \n",
    "        \n",
    "        qB_copy = torch.unsqueeze(self.weight.clone(),0) #--> new\n",
    "        qB1_copy = qB_copy #--> new\n",
    "        for i in range(self.M-1) : #--> new\n",
    "            qB_copy = torch.cat((qB_copy,qB1_copy),0) #--> new\n",
    "        self.qB = nn.Parameter(qB_copy) #--> new\n",
    "        \n",
    "        \n",
    "        # .....................................................input quantization \n",
    "        self.N = init_args['N']\n",
    "        \n",
    "        if self.N > 0 :\n",
    "            self.shift_v = init_args['shift_v']\n",
    "            a_sgn = init_args['a_sgn'] #--> scalar value\n",
    "            i_qargs = {'shift_init': self.shift_v,'N': self.N} #, 'a_sgn': torch.from_numpy(np.array([self.a_sgn]))}\n",
    "            self.register_buffer('a_sgn',  torch.from_numpy(np.array([a_sgn]))) #--> new (1X1) tensor\n",
    "            self.input_quantizer = ActQuantizer(**i_qargs) \n",
    "            self.b = (1/self.N)*torch.ones(self.N,1)\n",
    "        \n",
    "    #call it after loss.backward()\n",
    "    #---> specifically added for DeepLabv3+ (as last layer of ResNet-18 is not used by the code, so no gradient propagation from there)#KB(added on 01-08-2020)\n",
    "    def update_grads(self):\n",
    "        if self.qB.grad is not None :    \n",
    "            w_grad = 0.0\n",
    "            for i in range(self.M):\n",
    "                w_grad  += self.a[i][0]*self.qB.grad[i]\n",
    "            self.weight.grad = w_grad\n",
    "            \n",
    "    def update_a_sgn(self, epoch):\n",
    "        if self.N > 0:\n",
    "            self.a_sgn[0] = 1#1 - math.exp(-1*epoch/10) #self.a_sgn[0] + 0.05\n",
    "            if self.a_sgn[0] > 1.0:\n",
    "                self.a_sgn[0] = 1.0\n",
    "                \n",
    "    def update_a_sgn_val(self, epoch):\n",
    "        if self.N > 0:\n",
    "            self.a_sgn[0] = 1#1 - math.exp(-1*epoch/10) #1.0\n",
    "            if self.a_sgn[0] > 1.0:\n",
    "                self.a_sgn[0] = 1.0\n",
    "    \n",
    "    def forward(self, input):       \n",
    " # ----------------------------------------------------------------------------N=3(number of bases for input activations.)  \n",
    "        if self.N == 0 :    \n",
    "            self.a.data, self.qB.data = self.quantizer.quantize(self.weight)\n",
    "            out = 0.0\n",
    "            for i in range(self.M):\n",
    "                out  += self.a[i][0]*F.conv2d(input, self.qB[i], self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        else :\n",
    "            x = self.input_quantizer(input, self.a_sgn) # --> Input quantization\n",
    "            self.a.data, self.qB.data = self.quantizer.quantize(self.weight)\n",
    "            out = 0.0\n",
    "            for j in range(self.N):\n",
    "                out_temp = 0.0\n",
    "                for i in range(self.M):\n",
    "                    out_temp += self.a[i][0]*F.conv2d(x[j], self.qB[i], self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "                out += self.b[j][0]*out_temp\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PReLU(Function):    \n",
    "    @staticmethod\n",
    "    def forward(ctx, tensor, gamma, eta, beta): \n",
    "        x = tensor-gamma\n",
    "        ctx.save_for_backward(x, beta)\n",
    "        \n",
    "        y = x.clone() #-->.clone() is necessary, otherwise on changing y, x also changes and we don't want that.\n",
    "        z = x.clone()\n",
    "        y[y<=0]=0\n",
    "        z[z>0]=0\n",
    "        \n",
    "        #z = torch.tensor([0.0]).cuda()\n",
    "        #y = torch.max(x,z)[0] + beta*torch.min(x,z)[0]\n",
    "        y = y + beta*z\n",
    "        y = y + eta\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):        \n",
    "        # We return as many input gradients as there were arguments.\n",
    "        # Gradients of non-Tensor arguments to forward must be None.\n",
    "        g_o = grad_output.clone()\n",
    "        t,b = ctx.saved_tensors                                  \n",
    "        x = t.clone() #-->.clone() is necessary, otherwise on changing t, x also changes and we don't want that.\n",
    "        t[t<=0.0] = -1.0\n",
    "        t[t>0.0] = 0.0 \n",
    "        t = -1.0*t\n",
    "        grad_b_i = g_o*(x*t)\n",
    "        grad_g_i = g_o*(-t*b - (1.0 - t))  \n",
    "                                  \n",
    "        grad_input=g_o*(t*b + (1.0 - t))\n",
    "                                  \n",
    "        grad_g = (1/t.size()[0])*(torch.sum(torch.sum(torch.sum(grad_g_i,dim=0),dim=1),dim=1))\n",
    "        grad_gamma = grad_g.unsqueeze(0).unsqueeze(2).unsqueeze(2)\n",
    "                                  \n",
    "        grad_e = (1/t.size()[0])*(torch.sum(torch.sum(torch.sum(g_o,dim=0),dim=1),dim=1))\n",
    "        grad_eta = grad_e.unsqueeze(0).unsqueeze(2).unsqueeze(2)\n",
    "                                  \n",
    "        grad_b = (1/t.size()[0])*(torch.sum(torch.sum(torch.sum(grad_b_i,dim=0),dim=1),dim=1))\n",
    "        grad_beta = grad_b.unsqueeze(0).unsqueeze(2).unsqueeze(2)\n",
    "        return grad_input , grad_gamma, grad_eta, grad_beta\n",
    "                                                                            \n",
    "#-----------------------> (added on 17-08-2020)\n",
    "class PReLU_ActQuantizer(nn.ReLU) :\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(PReLU_ActQuantizer, self).__init__()\n",
    "        gamma = kwargs['gamma'] #this is a 1XC torch array.\n",
    "        gamma = gamma.unsqueeze(0).unsqueeze(2).unsqueeze(2)\n",
    "        self.gamma = nn.Parameter(gamma.float()) #initial clip_v value\n",
    "                                  \n",
    "        eta = kwargs['eta'] #this is a 1XC torch array.\n",
    "        eta = eta.unsqueeze(0).unsqueeze(2).unsqueeze(2)\n",
    "        self.eta = nn.Parameter(eta.float()) #initial clip_v value\n",
    "                                  \n",
    "        beta = kwargs['beta'] #this is a 1XC torch array.\n",
    "        beta = beta.unsqueeze(0).unsqueeze(2).unsqueeze(2)\n",
    "        self.beta = nn.Parameter(beta.float()) #initial clip_v value                          \n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = PReLU.apply(input, self.gamma, self.eta, self.beta)#-->new addition\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the gradients in the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_grads(net):\n",
    "    for n,m in net.named_modules():\n",
    "        if isinstance(m, QConv2d) :#or isinstance(m, QLinear):\n",
    "            m.update_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_a_sgn(net, epoch):\n",
    "    for n,m in net.named_modules():\n",
    "        if isinstance(m, QConv2d) :#or isinstance(m, QLinear):\n",
    "            m.update_a_sgn(epoch)\n",
    "            a_sgn = m.a_sgn #-->\n",
    "    return a_sgn #-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_a_sgn_val(net, epoch):\n",
    "    for n,m in net.named_modules():\n",
    "        if isinstance(m, QConv2d) :#or isinstance(m, QLinear):\n",
    "            m.update_a_sgn_val(epoch)\n",
    "            a_sgn = m.a_sgn #-->\n",
    "    return a_sgn #-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to load the full-precision state dict into the network\n",
    "Then reset the objects of type nn.Conv2d to QConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = -1 #--->\n",
    "N_val = 3\n",
    "\n",
    "for n,m in net.named_modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        n_channels = m.weight.size()[0] #---->\n",
    "        if n=='encoder.conv1': \n",
    "            #the first convlution layer remains as full-precision (first layer of ResNet-18 encoder) #it is called backbone.conv1 in DeepLabv3+ code.\n",
    "            continue\n",
    "        else :\n",
    "            #layer_id = int(n.partition('.')[-1].partition('.')[0]) #090719, AB: layer number for the conv layer\n",
    "            bias = False\n",
    "            if m.bias is not None:\n",
    "                bias = True\n",
    "            init_args = {'weight_data': m.weight.data,'bias_data': m.bias.data if bias else None, 'M':3, 'N':N_val, 'shift_v': torch.randn(N_val,m.weight.data.size()[1]*m.groups), 'a_sgn':1.0} #added the 'alpha' variable which will be initialized from previously learned values.\n",
    "            conv_args = {'in_channels': m.in_channels, 'out_channels': m.out_channels, 'kernel_size': m.kernel_size, 'stride': m.stride, 'padding': m.padding, 'groups': m.groups, 'bias': bias, 'dilation': m.dilation}\n",
    "            conv = QConv2d(init_args = init_args, **conv_args)\n",
    "            rsetattr(net,n, conv)\n",
    "            print('CONV layer '+ n+ ' quantized using '+ 'ABC-Net method')\n",
    "            \n",
    "    elif isinstance(m, nn.ReLU):#---->\n",
    "        i_qargs = {'gamma' : torch.randn(n_channels,), 'eta' : torch.randn(n_channels,), 'beta' : 0.25*torch.ones(n_channels,)}\n",
    "        relu = PReLU_ActQuantizer(**i_qargs)\n",
    "        rsetattr(net,n, relu)\n",
    "        print('RELU layer '+ n+ ' replaced using '+ 'ReAct-Net method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In your training code, ensure to include these to statements in the given order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "update_model_grads(segmentation_module) #----> new addition to update the parameters of quantized neural network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
